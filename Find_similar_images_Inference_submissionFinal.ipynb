{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coordinates retrieving of the closest image in the database - Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Workflow:\n",
    "\n",
    "* encoding images using transfert learning from pretrained ResNet model on a geographic zones classification task\n",
    "* binary hash images of training images in 512 feature space\n",
    "* retrieving the closest image to the one to identify in that feature space using Locality Sensitive Hashing for fast approximate nearest neighbor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import multiprocessing\n",
    "from tqdm import notebook\n",
    "import ast\n",
    "import sys\n",
    "import itertools\n",
    "import os\n",
    "from skimage import transform\n",
    "import cv2 as cv\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models, utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define path variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Define path to test data\n",
    "path_test_CSV = \"./data/piom_new_test_10k.csv\"\n",
    "path_test_image_folder = './data/piom_new_test_10k/'\n",
    "\n",
    "###Define path to models\n",
    "path_CNN = './models/gpu_model_resnet18.pth'\n",
    "path_LSH = './models/lsh.pkl'\n",
    "\n",
    "###Define path du submission CSV\n",
    "path_submission_CSV = \"submission.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Util functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MapDataset(Dataset):\n",
    "    def __init__(self, coordinateDf, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            coordinateDf (pd.DataFrame): DataFrame with image id and geographic coordinates.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.map_coordinates = coordinateDf\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.map_coordinates)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                self.map_coordinates.iloc[idx, 0] + '.png')\n",
    "        image = cv.imread(img_name)\n",
    "        image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        coordinates_crnr = np.array([self.map_coordinates['llcrnrlon'].iloc[idx], \n",
    "                            self.map_coordinates['llcrnrlat'].iloc[idx],\n",
    "                            self.map_coordinates['urcrnrlon'].iloc[idx], \n",
    "                            self.map_coordinates['urcrnrlat'].iloc[idx]]).astype('float')\n",
    "        sample = {'image': image,\n",
    "                  'Geo_zone': self.map_coordinates['Geo_zone'].iloc[idx],\n",
    "                  'image_path': img_name,\n",
    "                  'coordinates_crnr': coordinates_crnr}\n",
    "        return sample\n",
    "\n",
    "class Rescale(object):\n",
    "    \"\"\"Rescale the image in a sample to a given size.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If tuple, output is\n",
    "            matched to output_size. If int, smaller of image edges is matched\n",
    "            to output_size keeping aspect ratio the same.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, image):\n",
    "        h, w = image.shape[:2]\n",
    "        if isinstance(self.output_size, int):\n",
    "            if h > w:\n",
    "                new_h, new_w = self.output_size * h / w, self.output_size \n",
    "            else:\n",
    "                new_h, new_w = self.output_size, self.output_size * w / h\n",
    "        else:\n",
    "            new_h, new_w = self.output_size\n",
    "        new_h, new_w = int(new_h), int(new_w)\n",
    "        # image = transform.resize(image, (new_h, new_w), mode='reflect', anti_aliasing=True)\n",
    "        image = cv.resize(image, (new_h, new_w))\n",
    "        return image\n",
    "\n",
    "class SquareRescale(object):\n",
    "    \"\"\"Rescale the image in a sample to a given size.\"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, image):\n",
    "        image = cv.resize(image, (self.output_size, self.output_size))\n",
    "        # image = transform.resize(image, (self.output_size, self.output_size), mode='reflect', anti_aliasing=True)\n",
    "        return image\n",
    "\n",
    "\n",
    "class CenterCrop(object):\n",
    "    \"\"\"Crop the image in a sample centered to the middle of the image.\"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        if isinstance(output_size, int):\n",
    "            self.output_size = (output_size, output_size)\n",
    "        else:\n",
    "            assert len(output_size) == 2\n",
    "            self.output_size = output_size\n",
    "\n",
    "    def __call__(self, image):\n",
    "        h, w = image.shape[:2]\n",
    "        new_h, new_w = self.output_size\n",
    "        image = image[((h - new_h)//2): ((h - new_h)//2) + new_h,\n",
    "                      ((w - new_w)//2): ((w - new_w)//2) + new_w]\n",
    "        return image\n",
    "\n",
    "\n",
    "class Normalize(object):\n",
    "    \"\"\"Normalize the image.\"\"\"\n",
    "\n",
    "    def __init__(self, alpha, beta):\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "\n",
    "    def __call__(self, image):\n",
    "        image = cv.normalize(image, None, alpha=self.alpha, beta=self.beta, \n",
    "                    norm_type=cv.NORM_MINMAX, dtype=cv.CV_32F)\n",
    "        return image\n",
    "\n",
    "\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays to torch tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, image):\n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C X H X W\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        return torch.from_numpy(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoordinatesFromLSH():\n",
    "    \"\"\"Retrieve the coordinates from \"\"\"\n",
    "    def __init__( self, lsh, features ):\n",
    "        self.lsh = lsh\n",
    "        self.features = features\n",
    "    \n",
    "    def get_similar_item_image_coordinates(self, i_features):\n",
    "        try:\n",
    "            response = self.lsh.query(self.features[i_features].flatten(), \n",
    "                            num_results=1, distance_func='hamming')\n",
    "            return ast.literal_eval(response[0][0][1])\n",
    "        except IndexError as error:\n",
    "            print('Coordinate not found index: {}'.format(i_features))\n",
    "            return [0, 0, 0, 0]\n",
    "    \n",
    "    def get_coordinates_multiprocessing(self):\n",
    "        paramlist = list(range(len(self.features)))\n",
    "        #Generate processes equal to the number of cores\n",
    "        print('Getting coordinates...')\n",
    "        pool = multiprocessing.Pool(processes=multiprocessing.cpu_count())\n",
    "        Coordinates = list(notebook.tqdm(pool.map_async(\n",
    "            self.get_similar_item_image_coordinates, paramlist).get(), total=len(paramlist)))\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "        return Coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_inference(path_test_CSV, path_test_image_folder, path_CNN, path_LSH, path_submission_CSV, test_batch_size):\n",
    "    \n",
    "    startTime = time.time()\n",
    "    \n",
    "    ###======== Load CNN model ============\n",
    "    ###create model dropping last FC layer\n",
    "    model = models.resnet18(progress=True)\n",
    "    model = nn.Sequential(*list(model.children())[:-1])\n",
    "    ###model on GPU if GPU is available\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    ###load previously trained model parameters\n",
    "    model.load_state_dict(torch.load(path_CNN, map_location=device))\n",
    "    print(\"Model loaded from {}\".format(path_CNN))\n",
    "    # print(model)\n",
    "    \n",
    "    ###======== Load LSH model ============\n",
    "    lsh = pickle.load(open(path_LSH,'rb'))\n",
    "    print(\"LSH loaded from {}\".format(path_LSH))\n",
    "    \n",
    "    ###======== Test set dataloader ============\n",
    "    testDF = pd.read_csv(path_test_CSV)\n",
    "    testDF.drop(columns=[\"Unnamed: 0\"],inplace=True)\n",
    "    testDF['Geo_zone'] = np.nan\n",
    "    test_map_data = MapDataset(testDF, path_test_image_folder, transform= transforms.Compose([\n",
    "                                                       Rescale(225),\n",
    "                                                       CenterCrop((224,224)),\n",
    "                                                       Normalize(alpha=0., beta=1.),\n",
    "                                                       ToTensor(),\n",
    "                                                   ]))\n",
    "    test_loader = torch.utils.data.DataLoader(test_map_data,\n",
    "                                              batch_size=test_batch_size,\n",
    "                                              shuffle=False,\n",
    "                                              num_workers=multiprocessing.cpu_count(),\n",
    "                                              drop_last=False,\n",
    "                                              pin_memory=True)\n",
    "    print('Test data loader created, number of cores: {}'.format(multiprocessing.cpu_count()))\n",
    "\n",
    "    ###======= Test set forward pass========\n",
    "    total_step = len(test_loader)\n",
    "    test_features = []\n",
    "    for i_batch, sample_batch in enumerate(test_loader):\n",
    "        with torch.no_grad():\n",
    "            test_X = sample_batch['image'].float().to(device)\n",
    "            outputs = model(test_X)\n",
    "            test_features.extend(outputs.detach().cpu().numpy())\n",
    "        print('Batch: [{}/{}]'.format(i_batch+1, total_step), end=\"\\r\")\n",
    "    print('Test features created!')\n",
    "    \n",
    "    ###========= Retrieve coordinates from LSH domain ============\n",
    "\n",
    "    cooFromLSH = CoordinatesFromLSH(lsh, test_features)\n",
    "    Coordinates = cooFromLSH.get_coordinates_multiprocessing()\n",
    "    print('Coordinates retrieved!')\n",
    "    ###copy coordinates to test dataframe\n",
    "    # coordinates_transposed = zip(Coordinates)\n",
    "    testDF[[\"llcrnrlon\", \"llcrnrlat\", \"urcrnrlon\", \"urcrnrlat\"]] = pd.DataFrame(Coordinates)\n",
    "    print(testDF.head())\n",
    "    print(\"Test set - finding coordinates, time: {}h {}min {}s\".format((time.time()-startTime)//3600, \n",
    "                                                                      ((time.time()-startTime)%3600)//60,\n",
    "                                                                      (time.time()-startTime)%60))\n",
    "    testDF[[\"id\",\"llcrnrlon\",\"llcrnrlat\",\"urcrnrlon\",\"urcrnrlat\"]].to_csv(path_submission_CSV)\n",
    "    print('CSV file ready to submit, saved: {}'.format(path_submission_CSV))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    test_batch_size=50\n",
    "    main_inference(path_test_CSV, path_test_image_folder, path_CNN, path_LSH, path_submission_CSV, test_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "map_env",
   "language": "python",
   "name": "map_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
